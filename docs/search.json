[
	{
		"objectID": "index.html",
		"href": "index.html",
		"title": "Roo Code LLM Docs",
		"section": "",
		"text": "Welcome to the Roo Code Docs\nThis is the homepage for the Roo Code documentation.\nThis explains the codebase",
		"crumbs": [
			"<span class='chapter-number'>1</span>  <span class='chapter-title'>Welcome to the Roo Code Docs</span>"
		]
	},
	{
		"objectID": "llm_docs/overview.html",
		"href": "llm_docs/overview.html",
		"title": "Project Overview",
		"section": "",
		"text": "Key Areas\nThis project is a VS Code extension named “Roo Code” that provides AI-powered code assistance. It leverages large language models (LLMs) to provide features such as code completion, code generation, code explanation, and more.",
		"crumbs": [
			"Introduction",
			"<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Overview</span>"
		]
	},
	{
		"objectID": "llm_docs/overview.html#key-areas",
		"href": "llm_docs/overview.html#key-areas",
		"title": "Project Overview",
		"section": "",
		"text": "Core: Contains the core logic of the extension, including the Cline class, code action provider, and webview management. The core directory is responsible for managing the extension’s state, interacting with VS Code, and orchestrating the communication between different components.\nAPI: Defines the API for interacting with different language models (LLMs) and providers. The api directory provides a consistent interface for accessing various LLMs, such as OpenAI, Anthropic, and others.\nWebview UI: Implements the user interface using React, TypeScript, and Tailwind CSS. The webview-ui directory contains the code for the webview, which is used to display the user interface to the user.\nIntegrations: Integrates the extension with various VS Code features, such as diagnostics, editor actions, and terminal actions. The integrations directory contains the code for integrating the extension with VS Code’s features.\nServices: Provides various services, such as browser integration, MCP integration, and telemetry. The services directory contains the code for providing various services to the extension.",
		"crumbs": [
			"Introduction",
			"<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Overview</span>"
		]
	},
	{
		"objectID": "llm_docs/overview.html#top-level-files",
		"href": "llm_docs/overview.html#top-level-files",
		"title": "Project Overview",
		"section": "Top-Level Files",
		"text": "Top-Level Files\n\nsrc/extension.ts: The main entry point for the extension. This file is responsible for activating and deactivating the extension, registering commands, and initializing the various components.\nwebview-ui/src/App.tsx: The main component for the webview UI. This file defines the structure and layout of the UI.\npackage.json: Contains the extension’s metadata, dependencies, and build scripts. This file is used by VS Code to install and manage the extension.",
		"crumbs": [
			"Introduction",
			"<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Overview</span>"
		]
	},
	{
		"objectID": "llm_docs/overview.html#external-dependencies",
		"href": "llm_docs/overview.html#external-dependencies",
		"title": "Project Overview",
		"section": "External Dependencies",
		"text": "External Dependencies\n\nModel Context Protocol (MCP): Used for integrating with external tools and services. MCP allows the extension to communicate with other applications and services, such as code linters and formatters.\nLanguage Models (LLMs): Supports various LLMs through the API providers. The extension supports a variety of LLMs, allowing users to choose the model that best suits their needs.",
		"crumbs": [
			"Introduction",
			"<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Overview</span>"
		]
	},
	{
		"objectID": "llm_docs/overview.html#program-flow",
		"href": "llm_docs/overview.html#program-flow",
		"title": "Project Overview",
		"section": "Program Flow",
		"text": "Program Flow\n\nPlugin Initialization\nsequenceDiagram\n    participant VSCode as VS Code\n    participant Extension as src/extension.ts\n    participant ClineProvider as ClineProvider [[../src/core/webview/ClineProvider.ts]]\n    participant McpServerManager as McpServerManager [[../src/services/mcp/McpServerManager.ts]]\n    participant TelemetryService as TelemetryService [[../src/services/telemetry/TelemetryService.ts]]\n    participant TerminalRegistry as TerminalRegistry [[../src/integrations/terminal/TerminalRegistry.ts]]\n\n    VSCode-&gt;&gt;Extension: activate(context)\n    Extension-&gt;&gt;TelemetryService: initialize()\n    Extension-&gt;&gt;TerminalRegistry: initialize()\n    Extension-&gt;&gt;ClineProvider: new ClineProvider(context, outputChannel)\n    Extension-&gt;&gt;VSCode: registerWebviewViewProvider(ClineProvider.sideBarId, sidebarProvider)\n    Extension-&gt;&gt;VSCode: registerCommands(context, outputChannel, provider)\n    Extension-&gt;&gt;VSCode: registerTextDocumentContentProvider(DIFF_VIEW_URI_SCHEME, diffContentProvider)\n    Extension-&gt;&gt;VSCode: registerUriHandler(handleUri)\n    Extension-&gt;&gt;VSCode: registerCodeActionsProvider(pattern, new CodeActionProvider())\n    Extension-&gt;&gt;McpServerManager: cleanup(context)\n    Extension-&gt;&gt;TelemetryService: shutdown()\n    Extension-&gt;&gt;TerminalRegistry: cleanup()\n\n\nUser Chat Loop\n```mermaid sequenceDiagram participant User as User participant VSCode as VS Code participant ClineProvider as ClineProvider [[../src/core/webview/ClineProvider.ts]] participant Cline as Cline [[../src/core/Cline.ts]] participant APIProvider as APIProvider [[../src/api/providers/base-provider.ts]] participant LLM as LLM participant ToolManager as ToolManager\nUser-&gt;&gt;VSCode: Enters message in Cline\nVSCode-&gt;&gt;ClineProvider: postMessageToWebview({type: \"userMessage\", text: message})\nClineProvider-&gt;&gt;Cline: Handles user message\nCline-&gt;&gt;ToolManager: Determines if tool is needed\nalt Tool is needed\n    ToolManager-&gt;&gt;APIProvider: Sends request to tool\n    APIProvider-&gt;&gt;LLM: Sends request to LLM to use tool\n    LLM--&gt;&gt;APIProvider: Returns tool result\n    APIProvider-&gt;&gt;Cline: Transforms tool result\n    Cline-&gt;&gt;ClineProvider: postMessageToWebview({type: \"toolResult\", text: toolResult})\n    ClineProvider-&gt;&gt;VSCode: Displays tool result in Cline\n    VSCode-&gt;&gt;User: Displays tool result\nelse Tool is not needed\n    Cline-&gt;&gt;APIProvider: Sends message to API Provider\n    APIProvider-&gt;&gt;LLM: Sends request to LLM\n    LLM--&gt;&gt;APIProvider: Returns response\n    APIProvider-&gt;&gt;Cline: Transforms response\n    Cline-&gt;&gt;ClineProvider: postMessageToWebview({type: \"assistantMessage\", text: response})\n    ClineProvider-&gt;&gt;VSCode: Displays message in Cline\n    VSCode-&gt;&gt;User: Displays message\nend",
		"crumbs": [
			"Introduction",
			"<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Overview</span>"
		]
	},
	{
		"objectID": "llm_docs/extension.html",
		"href": "llm_docs/extension.html",
		"title": "Extension Activation",
		"section": "",
		"text": "Activation Process\nThe src/extension.ts file is the main entry point for the Roo Code extension. The activate function is called when the extension is activated. This function is responsible for initializing the extension and registering its various components.\nThe activate function performs the following tasks:",
		"crumbs": [
			"Core Architecture",
			"<span class='chapter-number'>3</span>  <span class='chapter-title'>Extension Activation</span>"
		]
	},
	{
		"objectID": "llm_docs/extension.html#activation-process",
		"href": "llm_docs/extension.html#activation-process",
		"title": "Extension Activation",
		"section": "",
		"text": "Load Environment Variables: The extension loads environment variables from the .env file using the dotenvx library. This allows the extension to access sensitive information, such as API keys, without hardcoding them in the code.\nInitialize Output Channel: The extension creates an output channel named “Roo-Code” for logging messages. This channel is used to display information about the extension’s status and any errors that occur.\nInitialize Telemetry Service: The extension initializes the telemetry service for collecting usage data. This data is used to track the usage of the extension and identify areas for improvement.\nInitialize Terminal Registry: The extension initializes the terminal registry for managing terminal-related commands and actions. This allows the extension to interact with the VS Code terminal.\nRegister Webview View Provider: The extension registers a webview view provider for the sidebar, which is used to display the user interface. The webview is a web-based view that is embedded in the VS Code editor.\nRegister Commands: The extension registers various commands, such as those for interacting with the LLMs and managing the extension’s settings. These commands are exposed to the user through the VS Code command palette.\nRegister Text Document Content Provider: The extension registers a text document content provider for displaying diff views. This allows the extension to display the differences between two versions of a file.\nRegister URI Handler: The extension registers a URI handler for handling custom URIs. This allows the extension to handle custom URIs that are used to communicate with the webview.\nRegister Code Actions Provider: The extension registers a code actions provider for providing suggestions and actions to the user based on the current code context. This allows the extension to provide context-aware assistance to the user.\nCreate Roo Code API: The extension creates the Roo Code API, which is used by other extensions to interact with the Roo Code extension. This allows other extensions to leverage the functionality of the Roo Code extension.",
		"crumbs": [
			"Core Architecture",
			"<span class='chapter-number'>3</span>  <span class='chapter-title'>Extension Activation</span>"
		]
	},
	{
		"objectID": "llm_docs/extension.html#deactivation-process",
		"href": "llm_docs/extension.html#deactivation-process",
		"title": "Extension Activation",
		"section": "Deactivation Process",
		"text": "Deactivation Process\nThe deactivate function is called when the extension is deactivated. It performs the following tasks:\n\nLog Deactivation Message: The extension logs a message to the output channel indicating that the extension has been deactivated.\nClean Up MCP Server Manager: The extension cleans up the MCP server manager, which is responsible for managing the MCP servers. This ensures that the MCP servers are properly shut down when the extension is deactivated.\nShutdown Telemetry Service: The extension shuts down the telemetry service. This ensures that no more telemetry data is collected when the extension is deactivated.\nClean Up Terminal Handlers: The extension cleans up the terminal handlers. This ensures that the terminal handlers are properly disposed of when the extension is deactivated.",
		"crumbs": [
			"Core Architecture",
			"<span class='chapter-number'>3</span>  <span class='chapter-title'>Extension Activation</span>"
		]
	},
	{
		"objectID": "llm_docs/extension.html#key-concepts",
		"href": "llm_docs/extension.html#key-concepts",
		"title": "Extension Activation",
		"section": "Key Concepts",
		"text": "Key Concepts\n\nActivation Events: Activation events are events that trigger the activation of the extension. The Roo Code extension uses several activation events, such as onView:roo-code-sidebar and onCommand:roo-code.chat.\nContribution Points: Contribution points are static declarations in the package.json file that extend VS Code. The Roo Code extension uses contribution points to register commands, settings, and other features.\nVS Code API: The VS Code API is a set of JavaScript APIs that you can invoke in your extension code. The Roo Code extension uses the VS Code API to interact with the VS Code editor, manage the webview, and register commands and settings.",
		"crumbs": [
			"Core Architecture",
			"<span class='chapter-number'>3</span>  <span class='chapter-title'>Extension Activation</span>"
		]
	},
	{
		"objectID": "llm_docs/core.html",
		"href": "llm_docs/core.html",
		"title": "Core Architecture",
		"section": "",
		"text": "Key Components\nThe core directory contains the core logic of the Roo Code extension. It manages the extension’s state, interacts with VS Code, and orchestrates the communication between different components.",
		"crumbs": [
			"Core Architecture",
			"<span class='chapter-number'>4</span>  <span class='chapter-title'>Core Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/core.html#key-components",
		"href": "llm_docs/core.html#key-components",
		"title": "Core Architecture",
		"section": "",
		"text": "Cline.ts: This file contains the main class for the extension, Cline. It is responsible for:\n\nManaging the overall state of the extension, including the current mode, API configuration, and task history.\nHandling user input and commands.\nInteracting with the LLMs through the API.\nOrchestrating the execution of tools and actions.\nCommunicating with the webview UI.\n\nCodeActionProvider.ts: This file implements the code action provider, which provides suggestions and actions to the user based on the current code context. It uses the VS Code API to register code actions and provide them to the user.\ncontextProxy.ts: This file manages the context proxy, which provides access to VS Code’s API and other extension-related information. It allows the core components to access VS Code functionality without directly importing the VS Code API.\nEditorUtils.ts: This file provides utility functions for interacting with the VS Code editor. These functions include:\n\nGetting the effective range of text.\nGetting the file path of a document.\nConverting VSCode Diagnostic objects to DiagnosticData instances.\nDetermining if two VSCode ranges intersect.\n\nmode-validator.ts: This file validates the current mode of the extension. It ensures that the user is in a valid mode and that the mode has the necessary permissions to perform the requested action.\nwebview/: This directory contains the code for managing the webview, which is used to display the user interface. It includes the ClineProvider class, which is responsible for creating and managing the webview panel.",
		"crumbs": [
			"Core Architecture",
			"<span class='chapter-number'>4</span>  <span class='chapter-title'>Core Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/core.html#relationships",
		"href": "llm_docs/core.html#relationships",
		"title": "Core Architecture",
		"section": "Relationships",
		"text": "Relationships\nThe core components interact with each other to provide the main functionality of the extension. For example:\n\nThe CodeActionProvider uses the EditorUtils to get information about the current code context and the Cline class to access the LLMs.\nThe Cline class uses the webview/ to display information to the user and the contextProxy to access VS Code functionality.",
		"crumbs": [
			"Core Architecture",
			"<span class='chapter-number'>4</span>  <span class='chapter-title'>Core Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/core.html#code-flow",
		"href": "llm_docs/core.html#code-flow",
		"title": "Core Architecture",
		"section": "Code Flow",
		"text": "Code Flow\n\nThe user enters a message in the Cline.\nThe ClineProvider receives the message and passes it to the Cline class.\nThe Cline class determines if a tool is needed based on the message.\nIf a tool is needed, the Cline class uses the appropriate tool to perform the requested action.\nIf a tool is not needed, the Cline class sends the message to the LLM through the API.\nThe LLM returns a response to the Cline class.\nThe Cline class transforms the response and sends it to the ClineProvider.\nThe ClineProvider displays the response in the Cline.",
		"crumbs": [
			"Core Architecture",
			"<span class='chapter-number'>4</span>  <span class='chapter-title'>Core Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/modes.html",
		"href": "llm_docs/modes.html",
		"title": "Modes",
		"section": "",
		"text": "Modes\nThe src/shared/modes.ts file defines the different modes of the extension. Each mode represents a different persona or role that the extension can adopt. The mode determines the system prompt, available tools, and other settings that are used to guide the LLM’s behavior.\nThe following modes are defined:",
		"crumbs": [
			"Core Architecture",
			"<span class='chapter-number'>5</span>  <span class='chapter-title'>Modes</span>"
		]
	},
	{
		"objectID": "llm_docs/modes.html#modes",
		"href": "llm_docs/modes.html#modes",
		"title": "Modes",
		"section": "",
		"text": "code: This mode is for general code editing and development. It provides access to a wide range of tools and is suitable for most coding tasks.\narchitect: This mode is for planning and designing the architecture of the codebase. It provides access to tools that are useful for analyzing and understanding the codebase.\nask: This mode is for asking questions about the codebase and getting information about software development. It provides access to tools that are useful for searching and retrieving information.\ndebug: This mode is for debugging the codebase. It provides access to tools that are useful for debugging, such as the debugger and the terminal.",
		"crumbs": [
			"Core Architecture",
			"<span class='chapter-number'>5</span>  <span class='chapter-title'>Modes</span>"
		]
	},
	{
		"objectID": "llm_docs/modes.html#mode-configuration",
		"href": "llm_docs/modes.html#mode-configuration",
		"title": "Modes",
		"section": "Mode Configuration",
		"text": "Mode Configuration\nEach mode has the following configuration properties:\n\nslug: A unique identifier for the mode. This is used to identify the mode in the code and in the settings.\nname: The display name for the mode. This is the name that is displayed to the user in the UI.\nroleDefinition: A description of the role of the mode. This is used to generate the system prompt that is sent to the LLM. The role definition should be a clear and concise description of the mode’s responsibilities and capabilities.\ncustomInstructions: Custom instructions for the mode. These instructions are appended to the role definition to further customize the behavior of the mode.\ngroups: The tool groups that are allowed for the mode. This property specifies which tools are available to the mode.",
		"crumbs": [
			"Core Architecture",
			"<span class='chapter-number'>5</span>  <span class='chapter-title'>Modes</span>"
		]
	},
	{
		"objectID": "llm_docs/modes.html#tool-groups",
		"href": "llm_docs/modes.html#tool-groups",
		"title": "Modes",
		"section": "Tool Groups",
		"text": "Tool Groups\nThe groups property specifies the tool groups that are allowed for the mode. The tool groups are defined in the src/shared/tool-groups.ts file. Tool groups are used to organize the available tools and to control which tools are available to each mode. This allows you to create specialized modes that are tailored to specific tasks.",
		"crumbs": [
			"Core Architecture",
			"<span class='chapter-number'>5</span>  <span class='chapter-title'>Modes</span>"
		]
	},
	{
		"objectID": "llm_docs/modes.html#adding-a-new-mode",
		"href": "llm_docs/modes.html#adding-a-new-mode",
		"title": "Modes",
		"section": "Adding a New Mode",
		"text": "Adding a New Mode\nTo add a new mode, you need to:\n\nDefine a new mode object in the src/shared/modes.ts file.\nSpecify the slug, name, roleDefinition, customInstructions, and groups properties for the new mode.\nRegister the new mode in the extension’s settings.",
		"crumbs": [
			"Core Architecture",
			"<span class='chapter-number'>5</span>  <span class='chapter-title'>Modes</span>"
		]
	},
	{
		"objectID": "llm_docs/llms.html",
		"href": "llm_docs/llms.html",
		"title": "Language Models (LLMs)",
		"section": "",
		"text": "Supported LLMs\nThe Roo Code extension supports various language models (LLMs) through the API providers in the src/api/providers directory. These LLMs are used to power the extension’s code generation, code completion, and other AI-powered features.\nThe following LLMs are currently supported:",
		"crumbs": [
			"Language Model Integration",
			"<span class='chapter-number'>6</span>  <span class='chapter-title'>Language Models (LLMs)</span>"
		]
	},
	{
		"objectID": "llm_docs/llms.html#supported-llms",
		"href": "llm_docs/llms.html#supported-llms",
		"title": "Language Models (LLMs)",
		"section": "",
		"text": "OpenAI: The OpenAI provider uses the OpenAI API to interact with the OpenAI models, such as GPT-3, GPT-4, and GPT-4o. OpenAI models are known for their strong performance on a wide range of tasks.\nAnthropic: The Anthropic provider uses the Anthropic API to interact with the Anthropic models, such as Claude. Claude models are known for their strong reasoning and natural language capabilities.\nBedrock: The Bedrock provider uses the AWS Bedrock API to interact with various LLMs available on AWS Bedrock. This allows the extension to support a wide range of models from different providers.\nGemini: The Gemini provider uses the Google Gemini API to interact with the Gemini models. Gemini models are known for their multimodal capabilities and strong performance on various tasks.\nMistral: The Mistral provider uses the Mistral API to interact with the Mistral models. Mistral models are known for their efficiency and performance.\nOllama: The Ollama provider uses the Ollama API to interact with the Ollama models. Ollama allows you to run models locally on your computer.\nLM Studio: The LM Studio provider uses the LM Studio API to interact with the LM Studio models. LM Studio allows you to run models locally on your computer.\nVertex: The Vertex provider uses the Google Vertex AI API to interact with the Vertex AI models. Vertex AI provides a platform for training and deploying machine learning models.\nDeepseek: The Deepseek provider uses the Deepseek API to interact with the Deepseek models. Deepseek models are known for their strong coding capabilities.\nOpenRouter: The OpenRouter provider uses the OpenRouter API to interact with various LLMs available on OpenRouter. OpenRouter provides a unified API for accessing multiple LLMs.\nVSCode-LM: The VSCode-LM provider uses the VSCode Language Model API to interact with local language models. This allows the extension to leverage local language models for code completion and other tasks.\nUnbound: The Unbound provider uses the Unbound API to interact with various LLMs available on Unbound.\nHuman Relay: The Human Relay provider allows the user to manually provide input for the LLMs. This can be useful for debugging or for tasks that require human intervention.",
		"crumbs": [
			"Language Model Integration",
			"<span class='chapter-number'>6</span>  <span class='chapter-title'>Language Models (LLMs)</span>"
		]
	},
	{
		"objectID": "llm_docs/llms.html#api-providers",
		"href": "llm_docs/llms.html#api-providers",
		"title": "Language Models (LLMs)",
		"section": "API Providers",
		"text": "API Providers\nEach LLM has its own API provider in the src/api/providers directory. The API providers implement the specific API calls and data transformations required for each LLM service. The base-provider.ts file defines the base class or interface for all LLM providers.",
		"crumbs": [
			"Language Model Integration",
			"<span class='chapter-number'>6</span>  <span class='chapter-title'>Language Models (LLMs)</span>"
		]
	},
	{
		"objectID": "llm_docs/llms.html#adding-a-new-llm-provider",
		"href": "llm_docs/llms.html#adding-a-new-llm-provider",
		"title": "Language Models (LLMs)",
		"section": "Adding a New LLM Provider",
		"text": "Adding a New LLM Provider\nTo add a new LLM provider, you need to:\n\nCreate a new file in the src/api/providers directory.\nImplement the BaseProvider interface in the new file.\nAdd the new provider to the ApiProvider type in the src/shared/api.ts file.\nUpdate the getCompletion function in the src/api/index.ts file to handle the new provider.",
		"crumbs": [
			"Language Model Integration",
			"<span class='chapter-number'>6</span>  <span class='chapter-title'>Language Models (LLMs)</span>"
		]
	},
	{
		"objectID": "llm_docs/api.html",
		"href": "llm_docs/api.html",
		"title": "API Architecture",
		"section": "",
		"text": "Key Components\nThe api directory defines the API for interacting with different language models (LLMs) and providers.",
		"crumbs": [
			"Language Model Integration",
			"<span class='chapter-number'>7</span>  <span class='chapter-title'>API Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/api.html#key-components",
		"href": "llm_docs/api.html#key-components",
		"title": "API Architecture",
		"section": "",
		"text": "index.ts: This file defines the main API entry point and provides functions for accessing the different LLM providers. It also includes functions for combining multiple API requests and handling errors.\nproviders/: This directory contains the implementations for the different LLM providers, such as OpenAI, Anthropic, and others. Each provider implements the BaseProvider interface and handles the specific API calls and data transformations required for each LLM service.\nproviders/base-provider.ts: This file defines the BaseProvider interface, which outlines the common methods that all LLM providers must implement. This ensures a consistent API for interacting with different LLMs.\nproviders/openai.ts: This file implements the OpenAI provider, which uses the OpenAI API to interact with the OpenAI models. It includes functions for making API calls, handling authentication (including Azure OpenAI), and transforming the data.\ntransform/: This directory contains the code for transforming the input and output of the LLM providers. This is necessary because different LLMs may have different input and output formats. The transformations ensure that the data is in the correct format for each LLM.",
		"crumbs": [
			"Language Model Integration",
			"<span class='chapter-number'>7</span>  <span class='chapter-title'>API Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/api.html#apiprovider-type",
		"href": "llm_docs/api.html#apiprovider-type",
		"title": "API Architecture",
		"section": "ApiProvider Type",
		"text": "ApiProvider Type\nThe ApiProvider type is a union of string literals that represent the different LLM providers supported by the extension. It is defined as follows:\nexport type ApiProvider =\n    | \"anthropic\"\n    | \"glama\"\n    | \"openrouter\"\n    | \"bedrock\" // AwsBedrockHandler\n    | \"vertex\"\n    | \"openai\"\n    | \"ollama\"\n    | \"lmstudio\"\n    | \"gemini\"\n    | \"openai-native\"\n    | \"deepseek\"\n    | \"vscode-lm\"\n    | \"mistral\"\n    | \"unbound\"\n    | \"requesty\"\n    | \"human-relay\"\nThis type is used to select the appropriate provider implementation based on the user’s configuration.",
		"crumbs": [
			"Language Model Integration",
			"<span class='chapter-number'>7</span>  <span class='chapter-title'>API Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/api.html#relationships",
		"href": "llm_docs/api.html#relationships",
		"title": "API Architecture",
		"section": "Relationships",
		"text": "Relationships\nThe API components interact with each other to provide a consistent interface for accessing the different LLMs. The index.ts file uses the providers/ to access the different LLMs, and the transform/ to transform the input and output of the LLMs.",
		"crumbs": [
			"Language Model Integration",
			"<span class='chapter-number'>7</span>  <span class='chapter-title'>API Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/api.html#external-apis",
		"href": "llm_docs/api.html#external-apis",
		"title": "API Architecture",
		"section": "External APIs",
		"text": "External APIs\nThis area interacts with external APIs such as OpenAI, Anthropic, etc. Each provider implements the specific API calls and data transformations required for each LLM service.",
		"crumbs": [
			"Language Model Integration",
			"<span class='chapter-number'>7</span>  <span class='chapter-title'>API Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/api.html#example-usage",
		"href": "llm_docs/api.html#example-usage",
		"title": "API Architecture",
		"section": "Example Usage",
		"text": "Example Usage\nHere’s an example of how to use the API to interact with an OpenAI model:\nimport { getCompletion } from \"../api\";\n\nasync function generateText(prompt: string, apiConfig: ApiConfiguration) {\n  try {\n    const result = await getCompletion(prompt, apiConfig);\n    return result.text;\n  } catch (error: any) {\n    console.error(\"Error generating text:\", error);\n    throw new Error(\\`Failed to generate text: \\${error.message}\\`);\n  }\n}\nThis example shows how to use the getCompletion function to generate text from an LLM. The apiConfig parameter specifies the API provider and model to use.",
		"crumbs": [
			"Language Model Integration",
			"<span class='chapter-number'>7</span>  <span class='chapter-title'>API Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/api.html#error-handling",
		"href": "llm_docs/api.html#error-handling",
		"title": "API Architecture",
		"section": "Error Handling",
		"text": "Error Handling\nThe API includes error handling to deal with issues such as API rate limits, authentication errors, and network connectivity problems. When an error occurs, the API will throw an exception with a descriptive error message. It is important to catch these exceptions and handle them appropriately.",
		"crumbs": [
			"Language Model Integration",
			"<span class='chapter-number'>7</span>  <span class='chapter-title'>API Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/api.html#data-transformations",
		"href": "llm_docs/api.html#data-transformations",
		"title": "API Architecture",
		"section": "Data Transformations",
		"text": "Data Transformations\nThe transform/ directory contains code for transforming the input and output of the LLM providers. For example, the transform/openai-format.ts file contains code for converting Anthropic messages into the format expected by the OpenAI API.",
		"crumbs": [
			"Language Model Integration",
			"<span class='chapter-number'>7</span>  <span class='chapter-title'>API Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/tool-selection.html",
		"href": "llm_docs/tool-selection.html",
		"title": "Tool Selection",
		"section": "",
		"text": "This document describes how the Roo Code extension determines whether a tool is required for a given user message.\nThe extension relies on the LLM to determine which tool is most appropriate for the current task. The extension provides the LLM with a list of available tools and a description of each tool. The LLM then uses this information to decide which tool to use, if any.\nThe extension uses a combination of techniques to guide the LLM’s tool selection process:\n\nSystem Prompt: The system prompt provides the LLM with a high-level overview of the available tools and their intended use cases. This helps the LLM understand the purpose of each tool and when it should be used.\nTool Descriptions: Each tool has a detailed description that explains its functionality and parameters. The LLM uses these descriptions to understand how to use the tool correctly.\nValidation: The extension validates the LLM’s tool selection to ensure that it is allowed for the current mode and that the required parameters are provided. This helps prevent the LLM from using tools that are not appropriate for the current task or from making mistakes in the tool usage.\n\nThe tool selection process is primarily handled in the recursivelyMakeClineRequests function in the src/core/Cline.ts file. This function calls the validateToolUse function to determine if a tool is allowed for the current mode. However, the actual selection of which tool to use is determined by the LLM itself.\nThe formatResponse.noToolsUsed() function is called when the LLM doesn’t use any tools. This function generates a message that prompts the LLM to either use a tool or attempt completion.\nIn summary, the tool selection process is a collaborative effort between the extension and the LLM. The extension provides the LLM with the necessary information and constraints, and the LLM uses this information to make the best decision about which tool to use.",
		"crumbs": [
			"Language Model Integration",
			"<span class='chapter-number'>8</span>  <span class='chapter-title'>Tool Selection</span>"
		]
	},
	{
		"objectID": "llm_docs/chat-flow.html",
		"href": "llm_docs/chat-flow.html",
		"title": "Chat Interaction Flow",
		"section": "",
		"text": "This document describes the flow of messages and MCP tool calls in the Roo Code extension.\n\n\n\n\n\nsequenceDiagram\n    participant User as User\n    participant VSCode as VS Code\n    participant ClineProvider as ClineProvider [[../src/core/webview/ClineProvider.ts]]\n    participant Cline as Cline [[../src/core/Cline.ts]]\n    participant APIProvider as APIProvider [[../src/api/providers/base-provider.ts]]\n    participant LLM as LLM\n    participant ToolManager as ToolManager\n    participant MCP as MCP Server\n\n    User-&gt;&gt;VSCode: Enters message in Cline\n    VSCode-&gt;&gt;ClineProvider: postMessageToWebview({type: \"userMessage\", text: message})\n    ClineProvider-&gt;&gt;Cline: Handles user message\n    Cline-&gt;&gt;ToolManager: Determines if tool is needed\n    alt Tool is needed\n        ToolManager-&gt;&gt;APIProvider: Sends request to tool\n        APIProvider-&gt;&gt;LLM: Sends request to LLM to use tool\n        LLM--&gt;&gt;APIProvider: Returns tool name and arguments\n        APIProvider-&gt;&gt;MCP: callTool(toolName, arguments)\n        MCP--&gt;&gt;APIProvider: Returns tool result\n        APIProvider-&gt;&gt;Cline: Transforms tool result\n        Cline-&gt;&gt;ClineProvider: postMessageToWebview({type: \"toolResult\", text: toolResult})\n        ClineProvider-&gt;&gt;VSCode: Displays tool result in Cline\n        VSCode-&gt;&gt;User: Displays tool result\n    else Tool is not needed\n        Cline-&gt;&gt;APIProvider: Sends message to API Provider\n        APIProvider-&gt;&gt;LLM: Sends request to LLM\n        LLM--&gt;&gt;APIProvider: Returns response\n        APIProvider-&gt;&gt;Cline: Transforms response\n        Cline-&gt;&gt;ClineProvider: postMessageToWebview({type: \"assistantMessage\", text: response})\n        ClineProvider-&gt;&gt;VSCode: Displays message in Cline\n        VSCode-&gt;&gt;User: Displays message\n    end",
		"crumbs": [
			"Language Model Integration",
			"<span class='chapter-number'>9</span>  <span class='chapter-title'>Chat Interaction Flow</span>"
		]
	},
	{
		"objectID": "llm_docs/mcp.html",
		"href": "llm_docs/mcp.html",
		"title": "MCP Integration",
		"section": "",
		"text": "Key Components\nThe src/services/mcp directory contains the code for integrating with the Model Context Protocol (MCP), which is used to communicate with external tools and services. MCP allows the Roo Code extension to leverage the capabilities of other applications and services, such as code linters, formatters, and documentation generators.",
		"crumbs": [
			"External Integrations",
			"<span class='chapter-number'>10</span>  <span class='chapter-title'>MCP Integration</span>"
		]
	},
	{
		"objectID": "llm_docs/mcp.html#key-components",
		"href": "llm_docs/mcp.html#key-components",
		"title": "MCP Integration",
		"section": "",
		"text": "McpServerManager.ts: This file manages the MCP server instances. It ensures that only one set of MCP servers runs across all webviews. The McpServerManager is responsible for starting, stopping, and restarting the MCP servers.\nMcpHub.ts: This file is the main class for managing the MCP connections. It is responsible for connecting to the MCP servers, fetching the tools and resources, and handling the communication between the extension and the MCP servers.",
		"crumbs": [
			"External Integrations",
			"<span class='chapter-number'>10</span>  <span class='chapter-title'>MCP Integration</span>"
		]
	},
	{
		"objectID": "llm_docs/mcp.html#mcp-server-management",
		"href": "llm_docs/mcp.html#mcp-server-management",
		"title": "MCP Integration",
		"section": "MCP Server Management",
		"text": "MCP Server Management\nThe McpServerManager class is a singleton that manages the MCP server instances. It provides the following functionalities:\n\ngetInstance(): Returns the singleton instance of the McpHub class. This ensures that only one instance of the McpHub class is created.\ncleanup(): Cleans up the singleton instance and all its resources. This is called when the extension is deactivated to ensure that all resources are properly released.",
		"crumbs": [
			"External Integrations",
			"<span class='chapter-number'>10</span>  <span class='chapter-title'>MCP Integration</span>"
		]
	},
	{
		"objectID": "llm_docs/mcp.html#mcp-connection-management",
		"href": "llm_docs/mcp.html#mcp-connection-management",
		"title": "MCP Integration",
		"section": "MCP Connection Management",
		"text": "MCP Connection Management\nThe McpHub class manages the MCP connections. It provides the following functionalities:\n\ngetServers(): Returns the list of enabled MCP servers. This allows the extension to discover the available MCP servers.\ngetAllServers(): Returns the list of all MCP servers, regardless of their state. This is useful for debugging and troubleshooting.\nconnectToServer(): Connects to an MCP server. This establishes a connection with the MCP server and allows the extension to access its tools and resources.\ndeleteConnection(): Deletes an MCP connection. This removes the connection from the list of available MCP servers.\nupdateServerConnections(): Updates the MCP server connections based on the settings file. This is called when the settings file is changed to ensure that the MCP connections are up-to-date.\nreadResource(): Reads a resource from an MCP server. This allows the extension to access data from the MCP server.\ncallTool(): Calls a tool on an MCP server. This allows the extension to execute a function on the MCP server.\ntoggleToolAlwaysAllow(): Toggles the always allow setting for a tool on an MCP server. This allows the user to control which tools are allowed to be executed automatically.",
		"crumbs": [
			"External Integrations",
			"<span class='chapter-number'>10</span>  <span class='chapter-title'>MCP Integration</span>"
		]
	},
	{
		"objectID": "llm_docs/mcp.html#mcp-settings",
		"href": "llm_docs/mcp.html#mcp-settings",
		"title": "MCP Integration",
		"section": "MCP Settings",
		"text": "MCP Settings\nThe MCP settings are stored in a JSON file named mcp_settings.json. The file contains a list of MCP servers, each with its own configuration. The configuration includes the command to run the server, the arguments to pass to the server, and the environment variables to set for the server.",
		"crumbs": [
			"External Integrations",
			"<span class='chapter-number'>10</span>  <span class='chapter-title'>MCP Integration</span>"
		]
	},
	{
		"objectID": "llm_docs/mcp.html#file-watching",
		"href": "llm_docs/mcp.html#file-watching",
		"title": "MCP Integration",
		"section": "File Watching",
		"text": "File Watching\nThe McpHub class uses chokidar to watch for changes in the MCP server files. When a change is detected, the McpHub class restarts the connection to the server. This ensures that the extension is always using the latest version of the MCP server.",
		"crumbs": [
			"External Integrations",
			"<span class='chapter-number'>10</span>  <span class='chapter-title'>MCP Integration</span>"
		]
	},
	{
		"objectID": "llm_docs/mcp.html#security-considerations",
		"href": "llm_docs/mcp.html#security-considerations",
		"title": "MCP Integration",
		"section": "Security Considerations",
		"text": "Security Considerations\nIt’s important to be aware of the security implications of using MCP. Since MCP allows external tools and services to interact with the extension, it’s important to carefully vet the MCP servers that you connect to. Only connect to MCP servers that you trust.",
		"crumbs": [
			"External Integrations",
			"<span class='chapter-number'>10</span>  <span class='chapter-title'>MCP Integration</span>"
		]
	},
	{
		"objectID": "llm_docs/services.html",
		"href": "llm_docs/services.html",
		"title": "Services Architecture",
		"section": "",
		"text": "Key Components\nThe services directory provides various services used by the Roo Code extension.",
		"crumbs": [
			"External Integrations",
			"<span class='chapter-number'>11</span>  <span class='chapter-title'>Services Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/services.html#key-components",
		"href": "llm_docs/services.html#key-components",
		"title": "Services Architecture",
		"section": "",
		"text": "browser/: This directory likely contains the code for integrating with a browser, allowing the extension to display web pages or interact with web-based services.\ncheckpoints/: This directory likely contains the code for managing checkpoints, which are used to save and restore the state of the extension.\nglob/: This directory likely contains the code for performing globbing operations, which are used to find files that match a certain pattern.\nmcp/: This directory contains the code for integrating with the Model Context Protocol (MCP), which is used to communicate with external tools and services.\nripgrep/: This directory likely contains the code for using ripgrep, a fast and efficient search tool.\ntelemetry/: This directory likely contains the code for collecting telemetry data, which is used to track the usage of the extension.\ntree-sitter/: This directory likely contains the code for using tree-sitter, a parser generator tool.",
		"crumbs": [
			"External Integrations",
			"<span class='chapter-number'>11</span>  <span class='chapter-title'>Services Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/services.html#relationships",
		"href": "llm_docs/services.html#relationships",
		"title": "Services Architecture",
		"section": "Relationships",
		"text": "Relationships\nThe service components likely interact with each other and with the core components to provide various functionalities for the extension. For example, the mcp/ might use the browser/ to display information from external tools and services, and the telemetry/ might be used to track the usage of the different services.",
		"crumbs": [
			"External Integrations",
			"<span class='chapter-number'>11</span>  <span class='chapter-title'>Services Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/webview-ui.html",
		"href": "llm_docs/webview-ui.html",
		"title": "Webview UI Architecture",
		"section": "",
		"text": "Key Components\nThe webview-ui directory implements the user interface for the Roo Code extension using React, TypeScript, and Tailwind CSS.",
		"crumbs": [
			"Webview UI",
			"<span class='chapter-number'>12</span>  <span class='chapter-title'>Webview UI Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/webview-ui.html#key-components",
		"href": "llm_docs/webview-ui.html#key-components",
		"title": "Webview UI Architecture",
		"section": "",
		"text": "src/App.tsx: This file is the main component for the webview UI and likely renders the main layout and components.\nsrc/index.tsx: This file is the entry point for the webview UI and likely initializes the React application.\nsrc/components/: This directory contains the reusable components used in the webview UI.\nsrc/context/: This directory likely contains the React context providers, which are used to manage the state of the webview UI.\nsrc/lib/: This directory likely contains utility functions and helper classes used in the webview UI.\nsrc/index.css: This file contains the CSS styles for the webview UI, including VSCode CSS variables.",
		"crumbs": [
			"Webview UI",
			"<span class='chapter-number'>12</span>  <span class='chapter-title'>Webview UI Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/webview-ui.html#technologies",
		"href": "llm_docs/webview-ui.html#technologies",
		"title": "Webview UI Architecture",
		"section": "Technologies",
		"text": "Technologies\n\nReact: A JavaScript library for building user interfaces.\nTypeScript: A superset of JavaScript that adds static typing.\nTailwind CSS: A utility-first CSS framework.\nVite: A build tool that provides fast development and optimized production builds.",
		"crumbs": [
			"Webview UI",
			"<span class='chapter-number'>12</span>  <span class='chapter-title'>Webview UI Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/webview-ui.html#relationships",
		"href": "llm_docs/webview-ui.html#relationships",
		"title": "Webview UI Architecture",
		"section": "Relationships",
		"text": "Relationships\nThe webview UI components likely interact with each other to provide the user interface for the extension. The App.tsx component might use the components in src/components/ to render the different parts of the UI, and the src/context/ might be used to manage the state of the UI.",
		"crumbs": [
			"Webview UI",
			"<span class='chapter-number'>12</span>  <span class='chapter-title'>Webview UI Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/webview-ui-structure.html",
		"href": "llm_docs/webview-ui-structure.html",
		"title": "Webview UI Structure",
		"section": "",
		"text": "Key Components\nThe webview-ui/src/App.tsx file is the main component for the webview UI. It defines the structure and layout of the UI.",
		"crumbs": [
			"Webview UI",
			"<span class='chapter-number'>13</span>  <span class='chapter-title'>Webview UI Structure</span>"
		]
	},
	{
		"objectID": "llm_docs/webview-ui-structure.html#key-components",
		"href": "llm_docs/webview-ui-structure.html#key-components",
		"title": "Webview UI Structure",
		"section": "",
		"text": "ChatView: This component displays the chat interface, where the user can interact with the LLMs.\nHistoryView: This component displays the chat history.\nSettingsView: This component displays the settings for the extension.\nMcpView: This component displays the MCP server management interface.\nPromptsView: This component displays the prompts management interface.\nWelcomeView: This component displays the welcome screen.\nHumanRelayDialog: This component displays a dialog for human relay, allowing the user to manually provide input for the LLMs.",
		"crumbs": [
			"Webview UI",
			"<span class='chapter-number'>13</span>  <span class='chapter-title'>Webview UI Structure</span>"
		]
	},
	{
		"objectID": "llm_docs/webview-ui-structure.html#state-management",
		"href": "llm_docs/webview-ui-structure.html#state-management",
		"title": "Webview UI Structure",
		"section": "State Management",
		"text": "State Management\nThe App component uses the ExtensionStateContext to manage the state of the UI. The ExtensionStateContext provides access to the following state variables:\n\ndidHydrateState\nshowWelcome\nshouldShowAnnouncement\ntelemetrySetting\ntelemetryKey\nmachineId",
		"crumbs": [
			"Webview UI",
			"<span class='chapter-number'>13</span>  <span class='chapter-title'>Webview UI Structure</span>"
		]
	},
	{
		"objectID": "llm_docs/webview-ui-structure.html#tab-navigation",
		"href": "llm_docs/webview-ui-structure.html#tab-navigation",
		"title": "Webview UI Structure",
		"section": "Tab Navigation",
		"text": "Tab Navigation\nThe App component uses a tab-based navigation system to switch between the different views. The tab state variable determines which view is currently displayed. The switchTab function is used to switch between the different views.",
		"crumbs": [
			"Webview UI",
			"<span class='chapter-number'>13</span>  <span class='chapter-title'>Webview UI Structure</span>"
		]
	},
	{
		"objectID": "llm_docs/webview-ui-structure.html#message-handling",
		"href": "llm_docs/webview-ui-structure.html#message-handling",
		"title": "Webview UI Structure",
		"section": "Message Handling",
		"text": "Message Handling\nThe App component uses the useEvent hook to listen for messages from the extension. When a message is received, the onMessage function is called. The onMessage function processes the message and updates the state of the UI accordingly.",
		"crumbs": [
			"Webview UI",
			"<span class='chapter-number'>13</span>  <span class='chapter-title'>Webview UI Structure</span>"
		]
	},
	{
		"objectID": "llm_docs/howto.html",
		"href": "llm_docs/howto.html",
		"title": "How-To Guide",
		"section": "",
		"text": "Changing System Prompts\nThis document provides guidance on how to perform common tasks in the Roo Code codebase. It serves as a practical guide for developers who want to contribute to the project or customize its functionality.\nFor a general overview of how VS Code extensions work, see the VS Code Extensions document.\nTo change the way system prompts work, you need to modify the src/shared/modes.ts file. This file defines the different modes of the extension, and each mode has a roleDefinition and customInstructions property that define the system prompt for that mode.",
		"crumbs": [
			"How-To Guides",
			"<span class='chapter-number'>14</span>  <span class='chapter-title'>How-To Guide</span>"
		]
	},
	{
		"objectID": "llm_docs/howto.html#changing-system-prompts",
		"href": "llm_docs/howto.html#changing-system-prompts",
		"title": "How-To Guide",
		"section": "",
		"text": "Edit the src/shared/modes.ts file. This file contains the configuration for all the available modes.\nFind the mode configuration you want to modify. The modes array contains the configuration for each mode. Each mode object has properties like slug, name, roleDefinition, and customInstructions.\nUpdate the roleDefinition and/or customInstructions property. The roleDefinition property defines the role of the mode, and the customInstructions property provides custom instructions for the mode. These properties are used to generate the system prompt that is sent to the LLM.\n\nExample: typescript     {         slug: \"code\",         name: \"Code\",         roleDefinition: \"You are Roo, a highly skilled software engineer...\",         customInstructions: \"Follow these instructions carefully...\",         groups: [\"read\", \"edit\", \"command\"],     }",
		"crumbs": [
			"How-To Guides",
			"<span class='chapter-number'>14</span>  <span class='chapter-title'>How-To Guide</span>"
		]
	},
	{
		"objectID": "llm_docs/howto.html#adding-a-new-chat-ui-element",
		"href": "llm_docs/howto.html#adding-a-new-chat-ui-element",
		"title": "How-To Guide",
		"section": "Adding a New Chat UI Element",
		"text": "Adding a New Chat UI Element\nTo add a new chat UI element, you need to modify the webview-ui/src/components/chat/ChatView.tsx file. This file defines the chat interface.\n\nEdit the webview-ui/src/components/chat/ChatView.tsx file. This file contains the React component that renders the chat interface.\nAdd the corresponding React component to the ChatView component. You can add the component to the existing layout or create a new layout for the component. Consider using existing UI components from webview-ui/src/components/ui to maintain a consistent look and feel.\nUpdate the state management logic to handle the new UI element. You may need to add new state variables to the ChatView component and update the event handlers to handle the new UI element. Use React’s useState hook to manage the state of the UI element.",
		"crumbs": [
			"How-To Guides",
			"<span class='chapter-number'>14</span>  <span class='chapter-title'>How-To Guide</span>"
		]
	},
	{
		"objectID": "llm_docs/howto.html#adding-additional-settings-pages",
		"href": "llm_docs/howto.html#adding-additional-settings-pages",
		"title": "How-To Guide",
		"section": "Adding Additional Settings Pages",
		"text": "Adding Additional Settings Pages\nTo add additional settings pages, you need to modify the webview-ui/src/components/settings/SettingsView.tsx file. This file defines the settings interface.\n\nEdit the webview-ui/src/components/settings/SettingsView.tsx file. This file contains the React component that renders the settings interface.\nAdd a new tab to the settings interface. You can use the existing tab component or create a new tab component. Use a UI library like vscrui or the VS Code Toolkit to create the tab.\nCreate a new React component for the settings page. This component will display the settings for the new page.\nUpdate the state management logic to handle the new settings. You may need to add new state variables to the SettingsView component and update the event handlers to handle the new settings.",
		"crumbs": [
			"How-To Guides",
			"<span class='chapter-number'>14</span>  <span class='chapter-title'>How-To Guide</span>"
		]
	},
	{
		"objectID": "llm_docs/howto.html#adding-a-new-ui-panel",
		"href": "llm_docs/howto.html#adding-a-new-ui-panel",
		"title": "How-To Guide",
		"section": "Adding a New UI Panel",
		"text": "Adding a New UI Panel\nTo add a new UI Panel, you need to modify the src/extension.ts file. This file is the main entry point for the extension.\n\nEdit the src/extension.ts file.\nRegister a new webview view provider in the activate function. You can use the vscode.window.registerWebviewViewProvider function to register a new webview view provider.\nCreate a new React component for the UI panel. This component will display the content of the UI panel. The component should be placed in the webview-ui/src/components directory.\nUpdate the state management logic to handle the new UI panel. You may need to add new state variables to the extension and update the event handlers to handle the new UI panel.",
		"crumbs": [
			"How-To Guides",
			"<span class='chapter-number'>14</span>  <span class='chapter-title'>How-To Guide</span>"
		]
	},
	{
		"objectID": "llm_docs/howto.html#adding-extensions-to-roo",
		"href": "llm_docs/howto.html#adding-extensions-to-roo",
		"title": "How-To Guide",
		"section": "Adding Extensions to ROO",
		"text": "Adding Extensions to ROO\nTo add extensions to ROO, you need to modify the package.json file. This file contains the extension’s metadata, dependencies, and build scripts.\n\nEdit the package.json file.\nAdd the extension as a dependency in the package.json file. You can use the npm install command to add the extension as a dependency.\nUpdate the build scripts to include the extension in the build process. You may need to modify the esbuild.js file to include the extension in the build process.",
		"crumbs": [
			"How-To Guides",
			"<span class='chapter-number'>14</span>  <span class='chapter-title'>How-To Guide</span>"
		]
	},
	{
		"objectID": "llm_docs/howto.html#how-to-run-tests",
		"href": "llm_docs/howto.html#how-to-run-tests",
		"title": "How-To Guide",
		"section": "How to Run Tests",
		"text": "How to Run Tests\nTo run tests, you can use the following command:\nnpm run test\nThis command will run all the tests in the project. The test files are located in the src/__tests__ and webview-ui/src/__tests__ directories.",
		"crumbs": [
			"How-To Guides",
			"<span class='chapter-number'>14</span>  <span class='chapter-title'>How-To Guide</span>"
		]
	},
	{
		"objectID": "llm_docs/howto.html#how-to-modify-the-mcp-tool-calls",
		"href": "llm_docs/howto.html#how-to-modify-the-mcp-tool-calls",
		"title": "How-To Guide",
		"section": "How to Modify the MCP Tool Calls",
		"text": "How to Modify the MCP Tool Calls\nTo modify the MCP tool calls, you need to modify the src/services/mcp/McpHub.ts file. This file contains the code for calling the MCP tools.\n\nEdit the src/services/mcp/McpHub.ts file.\nFind the callTool function. This function is responsible for calling the MCP tools.\nModify the callTool function to change the way the MCP tools are called. You can modify the arguments that are passed to the tools or the way the results are handled.",
		"crumbs": [
			"How-To Guides",
			"<span class='chapter-number'>14</span>  <span class='chapter-title'>How-To Guide</span>"
		]
	},
	{
		"objectID": "llm_docs/howto.html#how-to-launch-child-tasks",
		"href": "llm_docs/howto.html#how-to-launch-child-tasks",
		"title": "How-To Guide",
		"section": "How to Launch Child Tasks",
		"text": "How to Launch Child Tasks\nTo launch child tasks, you can use the newTask tool. This tool allows you to create a new task with a specified mode and initial message.\n\nUse the newTask tool to create a new task. You need to specify the mode and initial message for the new task.\nThe new task will be launched in a new Cline instance.",
		"crumbs": [
			"How-To Guides",
			"<span class='chapter-number'>14</span>  <span class='chapter-title'>How-To Guide</span>"
		]
	},
	{
		"objectID": "llm_docs/howto.html#how-to-chain-agents-together",
		"href": "llm_docs/howto.html#how-to-chain-agents-together",
		"title": "How-To Guide",
		"section": "How to Chain Agents Together",
		"text": "How to Chain Agents Together\nTo chain agents together, you can use the newTask tool to launch a new task with a specific mode and initial message. The new task can then use the newTask tool to launch another task, and so on. This allows you to create a chain of agents that can work together to accomplish a complex task.\n\nUse the newTask tool to launch the first agent in the chain. You need to specify the mode and initial message for the first agent.\nIn the first agent, use the newTask tool to launch the second agent in the chain. You need to specify the mode and initial message for the second agent.\nRepeat step 2 for each agent in the chain.\nThe agents will be launched in a sequence, with each agent passing its results to the next agent in the chain.",
		"crumbs": [
			"How-To Guides",
			"<span class='chapter-number'>14</span>  <span class='chapter-title'>How-To Guide</span>"
		]
	},
	{
		"objectID": "llm_docs/howto.html#how-to-have-a-chain-with-a-coordinator-agent",
		"href": "llm_docs/howto.html#how-to-have-a-chain-with-a-coordinator-agent",
		"title": "How-To Guide",
		"section": "How to Have a Chain with a Coordinator Agent",
		"text": "How to Have a Chain with a Coordinator Agent\nTo have a chain with a coordinator agent, you can use the newTask tool to launch a coordinator agent. The coordinator agent can then use the newTask tool to launch the other agents in the chain. The coordinator agent can be responsible for coordinating the work of the other agents and for combining their results.\n\nUse the newTask tool to launch the coordinator agent. You need to specify the mode and initial message for the coordinator agent. The initial message should describe the overall task and the roles of the other agents.\nIn the coordinator agent, use the newTask tool to launch the other agents in the chain. You need to specify the mode and initial message for each agent. The initial message should describe the specific task that each agent is responsible for.\nThe coordinator agent can then use the results from the other agents to accomplish the overall task. The coordinator agent can use the read_file tool to read the results from the other agents and the apply_diff tool to combine the results.",
		"crumbs": [
			"How-To Guides",
			"<span class='chapter-number'>14</span>  <span class='chapter-title'>How-To Guide</span>"
		]
	},
	{
		"objectID": "llm_docs/howto.html#does-this-codebase-support-sub-sub-tasks",
		"href": "llm_docs/howto.html#does-this-codebase-support-sub-sub-tasks",
		"title": "How-To Guide",
		"section": "Does this codebase support sub sub tasks?",
		"text": "Does this codebase support sub sub tasks?\nWhile there’s no explicit code preventing the creation of sub-sub-tasks (a task launched from a child task), full support isn’t guaranteed. The system is designed to launch child tasks, but the implications of deeply nested task chains haven’t been fully explored. Use with caution.\nFor information on how to add a new setting to the extension, see the Settings document.\nFor information on how the extension determines if a tool is required, see the Tool Selection document.",
		"crumbs": [
			"How-To Guides",
			"<span class='chapter-number'>14</span>  <span class='chapter-title'>How-To Guide</span>"
		]
	},
	{
		"objectID": "llm_docs/settings.html",
		"href": "llm_docs/settings.html",
		"title": "Settings",
		"section": "",
		"text": "Adding a New Setting\nThis document describes how the settings are managed in the Roo Code extension.\nTo add a new setting that persists its state, follow these steps:\nThese steps ensure that:",
		"crumbs": [
			"How-To Guides",
			"<span class='chapter-number'>15</span>  <span class='chapter-title'>Settings</span>"
		]
	},
	{
		"objectID": "llm_docs/settings.html#adding-a-new-setting",
		"href": "llm_docs/settings.html#adding-a-new-setting",
		"title": "Settings",
		"section": "",
		"text": "For All Settings:\n\nAdd the setting to src/shared/ExtensionMessage.ts:\n\nAdd the setting to the ExtensionState interface.\nMake it required if it has a default value, optional if it can be undefined.\nExample: preferredLanguage: string\n\nAdd test coverage:\n\nAdd the setting to mockState in src/activate/ClineProvider.test.ts.\nAdd test cases for setting persistence and state updates.\nEnsure all tests pass before submitting changes.\n\n\nFor Checkbox Settings:\n\nAdd the message type to webview-ui/src/WebviewMessage.ts:\n\nAdd the setting name to the WebviewMessage type’s type union.\nExample: | \"multisearchDiffEnabled\"\n\nAdd the setting to webview-ui/src/context/ExtensionStateContext.tsx:\n\nAdd the setting to the ExtensionStateContextType interface.\nAdd the setter function to the interface.\nAdd the setting to the initial state in useState.\nAdd the setting to the contextValue object.\nExample: typescript     interface ExtensionStateContextType {         multisearchDiffEnabled: boolean         setMultisearchDiffEnabled: (value: boolean) =&gt; void     }\n\nAdd the setting to src/activate/ClineProvider.ts:\n\nAdd the setting name to the GlobalStateKey type union.\nAdd the setting to the Promise.all array in getState.\nAdd the setting to the return value in getState with a default value.\nAdd the setting to the destructured variables in getStateToPostToWebview.\nAdd the setting to the return value in getStateToPostToWebview.\nAdd a case in setWebviewMessageListener to handle the setting’s message type.\nExample: typescript     case \"multisearchDiffEnabled\":       await this.updateGlobalState(\"multisearchDiffEnabled\", message.bool)       await this.postStateToWebview()       break\n\nAdd the checkbox UI to webview-ui/src/components/settings/SettingsView.tsx:\n\nImport the setting and its setter from ExtensionStateContext.\nAdd the VSCodeCheckbox component with the setting’s state and onChange handler.\nAdd appropriate labels and description text.\nExample: typescript     &lt;VSCodeCheckbox       checked={multisearchDiffEnabled}       onChange={(e: any) =&gt; setMultisearchDiffEnabled(e.target.checked)}     &gt;       &lt;span style={{ fontWeight: \"500\" }}&gt;Enable multi-search diff matching&lt;/span&gt;     &lt;/VSCodeCheckbox&gt;\n\nAdd the setting to handleSubmit in webview-ui/src/components/settings/SettingsView.tsx:\n\nAdd a vscode.postMessage call to send the setting’s value when clicking Done.\nExample: typescript     vscode.postMessage({ type: \"multisearchDiffEnabled\", bool: multisearchDiffEnabled })\n\n\nFor Select/Dropdown Settings:\n\nAdd the message type to webview-ui/src/WebviewMessage.ts:\n\nAdd the setting name to the WebviewMessage type’s type union.\nExample: | \"preferredLanguage\"\n\nAdd the setting to webview-ui/src/context/ExtensionStateContext.tsx:\n\nAdd the setting to the ExtensionStateContextType interface.\nAdd the setter function to the interface.\nAdd the setting to the initial state in useState with a default value.\nAdd the setting to the contextValue object.\nExample: typescript     interface ExtensionStateContextType {         preferredLanguage: string         setPreferredLanguage: (value: string) =&gt; void     }\n\nAdd the setting to src/activate/ClineProvider.ts:\n\nAdd the setting name to the GlobalStateKey type union.\nAdd the setting to the Promise.all array in getState.\nAdd the setting to the return value in getState with a default value.\nAdd the setting to the destructured variables in getStateToPostToWebview.\nAdd the setting to the return value in getStateToPostToWebview.\nAdd a case in setWebviewMessageListener to handle the setting’s message type.\nExample: typescript     case \"preferredLanguage\":       await this.updateGlobalState(\"preferredLanguage\", message.text)       await this.postStateToWebview()       break\n\nAdd the select UI to webview-ui/src/components/settings/SettingsView.tsx:\n\nImport the setting and its setter from ExtensionStateContext.\nAdd the select element with appropriate styling to match VSCode’s theme.\nAdd options for the dropdown.\nAdd appropriate labels and description text.\nExample: typescript     &lt;select       value={preferredLanguage}       onChange={(e) =&gt; setPreferredLanguage(e.target.value)}       style={{         width: \"100%\",         padding: \"4px 8px\",         backgroundColor: \"var(--vscode-input-background)\",         color: \"var(--vscode-input-foreground)\",         border: \"1px solid var(--vscode-input-border)\",         borderRadius: \"2px\"       }}&gt;       &lt;option value=\"English\"&gt;English&lt;/option&gt;       &lt;option value=\"Spanish\"&gt;Spanish&lt;/option&gt;       ...     &lt;/select&gt;\n\nAdd the setting to handleSubmit in webview-ui/src/components/settings/SettingsView.tsx:\n\nAdd a vscode.postMessage call to send the setting’s value when clicking Done.\nExample: typescript     vscode.postMessage({ type: \"preferredLanguage\", text: preferredLanguage })\n\n\n\n\n\nThe setting’s state is properly typed throughout the application.\nThe setting persists between sessions.\nThe setting’s value is properly synchronized between the webview and extension.\nThe setting has a proper UI representation in the settings view.\nTest coverage is maintained for the new setting.",
		"crumbs": [
			"How-To Guides",
			"<span class='chapter-number'>15</span>  <span class='chapter-title'>Settings</span>"
		]
	},
	{
		"objectID": "llm_docs/cost.html",
		"href": "llm_docs/cost.html",
		"title": "Cost Calculation",
		"section": "",
		"text": "Functions\nThe src/utils/cost.ts file defines functions for calculating the cost of using the LLMs. Understanding cost calculation is crucial for managing the extension’s resource consumption and providing users with transparent pricing information.\nThe following functions are defined:",
		"crumbs": [
			"Utilities",
			"<span class='chapter-number'>16</span>  <span class='chapter-title'>Cost Calculation</span>"
		]
	},
	{
		"objectID": "llm_docs/cost.html#functions",
		"href": "llm_docs/cost.html#functions",
		"title": "Cost Calculation",
		"section": "",
		"text": "calculateApiCostInternal(modelInfo, inputTokens, outputTokens, cacheCreationInputTokens, cacheReadInputTokens): Calculates the cost based on the model info, input tokens, output tokens, cache creation input tokens, and cache read input tokens. This function serves as a central point for cost calculation, taking into account various factors that influence the overall cost.\ncalculateApiCostAnthropic(modelInfo, inputTokens, outputTokens, cacheCreationInputTokens, cacheReadInputTokens): Calculates the cost specifically for Anthropic compliant usage. This function applies Anthropic’s pricing model to the token counts.\ncalculateApiCostOpenAI(modelInfo, inputTokens, outputTokens, cacheCreationInputTokens, cacheReadInputTokens): Calculates the cost specifically for OpenAI compliant usage. This function applies OpenAI’s pricing model to the token counts.\nparseApiPrice(price): Parses the API price. This function is used to extract the price from the model info.",
		"crumbs": [
			"Utilities",
			"<span class='chapter-number'>16</span>  <span class='chapter-title'>Cost Calculation</span>"
		]
	},
	{
		"objectID": "llm_docs/cost.html#cost-calculation-factors",
		"href": "llm_docs/cost.html#cost-calculation-factors",
		"title": "Cost Calculation",
		"section": "Cost Calculation Factors",
		"text": "Cost Calculation Factors\nThe cost is calculated based on the following factors:\n\nModel info: This includes the model’s input price, output price, context window size, and other relevant information. The model info is used to determine the cost per token.\nInput tokens: The number of tokens in the input prompt. The input tokens contribute to the overall cost based on the model’s input price.\nOutput tokens: The number of tokens in the LLM’s response. The output tokens contribute to the overall cost based on the model’s output price.\nCache creation input tokens: The number of input tokens used to create the cache. Cache creation contributes to the overall cost.\nCache read input tokens: The number of input tokens used to read from the cache. Cache reads contribute to the overall cost, but typically at a lower rate than cache creation.",
		"crumbs": [
			"Utilities",
			"<span class='chapter-number'>16</span>  <span class='chapter-title'>Cost Calculation</span>"
		]
	},
	{
		"objectID": "llm_docs/cost.html#example",
		"href": "llm_docs/cost.html#example",
		"title": "Cost Calculation",
		"section": "Example",
		"text": "Example\nHere’s an example of how the cost is calculated:\nconst modelInfo = {\n  inputPrice: 0.0001, // $0.0001 per 1000 tokens\n  outputPrice: 0.0002, // $0.0002 per 1000 tokens\n  contextWindow: 4096,\n  supportsImages: false,\n  supportsPromptCache: false,\n};\n\nconst inputTokens = 1000;\nconst outputTokens = 500;\n\nconst cost = calculateApiCostInternal(modelInfo, inputTokens, outputTokens, 0, 0);\n\nconsole.log(\\`Cost: \\${cost}\\`); // Output: Cost: 0.0002\nIn this example, the cost is calculated as follows:\n\nInput cost: 1000 tokens * $0.0001/1000 tokens = $0.0001\nOutput cost: 500 tokens * $0.0002/1000 tokens = $0.0001\nTotal cost: $0.0001 + $0.0001 = $0.0002",
		"crumbs": [
			"Utilities",
			"<span class='chapter-number'>16</span>  <span class='chapter-title'>Cost Calculation</span>"
		]
	},
	{
		"objectID": "llm_docs/fs.html",
		"href": "llm_docs/fs.html",
		"title": "File System Utilities",
		"section": "",
		"text": "Functions\nThe src/utils/fs.ts file defines utility functions for working with the file system. These functions provide a convenient way to perform common file system operations.\nThe following functions are defined:",
		"crumbs": [
			"Utilities",
			"<span class='chapter-number'>17</span>  <span class='chapter-title'>File System Utilities</span>"
		]
	},
	{
		"objectID": "llm_docs/fs.html#functions",
		"href": "llm_docs/fs.html#functions",
		"title": "File System Utilities",
		"section": "",
		"text": "createDirectoriesForFile(filePath): Creates all non-existing subdirectories for a given file path. This function ensures that the directory structure exists before writing a file to disk.\n\nParameters:\n\nfilePath: The path to the file.\n\nExample:\nimport { createDirectoriesForFile } from \"../utils/fs\";\n\nconst filePath = \"/path/to/my/file.txt\";\nawait createDirectoriesForFile(filePath);\n// The directories /path/to/my/ will be created if they don't exist.\n\nfileExistsAtPath(filePath): Checks if a path exists. This function can be used to determine whether a file or directory exists before attempting to access it.\n\nParameters:\n\nfilePath: The path to check.\n\nReturns: true if the path exists, false otherwise.\nExample: ```typescript import { fileExistsAtPath } from “../utils/fs”;\nconst filePath = “/path/to/my/file.txt”; const exists = await fileExistsAtPath(filePath); if (exists) { console.log(“File exists!”); } else { console.log(“File does not exist.”); }",
		"crumbs": [
			"Utilities",
			"<span class='chapter-number'>17</span>  <span class='chapter-title'>File System Utilities</span>"
		]
	},
	{
		"objectID": "llm_docs/git.html",
		"href": "llm_docs/git.html",
		"title": "Git Utilities",
		"section": "",
		"text": "Functions\nThe src/utils/git.ts file defines utility functions for working with Git repositories. These functions provide a convenient way to interact with Git from within the extension.\nThe following functions are defined:",
		"crumbs": [
			"Utilities",
			"<span class='chapter-number'>18</span>  <span class='chapter-title'>Git Utilities</span>"
		]
	},
	{
		"objectID": "llm_docs/git.html#functions",
		"href": "llm_docs/git.html#functions",
		"title": "Git Utilities",
		"section": "",
		"text": "searchCommits(query, cwd): Searches for commits matching a query in the specified working directory. This function allows you to find commits that contain specific keywords or patterns.\n\nParameters:\n\nquery: The search query.\ncwd: The working directory to search in.\n\nReturns: A promise that resolves to an array of commit objects.\nExample:\nimport { searchCommits } from \"../utils/git\";\n\nconst commits = await searchCommits(\"fix: bug\", \"/path/to/repo\");\nconsole.log(commits);\n\ngetCommitInfo(hash, cwd): Retrieves information about a specific commit in the specified working directory. This function allows you to get details about a commit, such as the author, date, and message.\n\nParameters:\n\nhash: The commit hash.\ncwd: The working directory to search in.\n\nReturns: A promise that resolves to a commit object.\nExample:\nimport { getCommitInfo } from \"../utils/git\";\n\nconst commit = await getCommitInfo(\"a1b2c3d4e5f6\", \"/path/to/repo\");\nconsole.log(commit);\n\ngetWorkingState(cwd): Retrieves the status of the working directory. This function allows you to check if there are any uncommitted changes in the working directory.\n\nParameters:\n\ncwd: The working directory to check.\n\nReturns: A promise that resolves to an object containing the working directory status.\nExample: ```typescript import { getWorkingState } from “../utils/git”;\nconst workingState = await getWorkingState(“/path/to/repo”); console.log(workingState);",
		"crumbs": [
			"Utilities",
			"<span class='chapter-number'>18</span>  <span class='chapter-title'>Git Utilities</span>"
		]
	},
	{
		"objectID": "llm_docs/messages.html",
		"href": "llm_docs/messages.html",
		"title": "Extension Messages",
		"section": "",
		"text": "Message Types\nThe src/shared/ExtensionMessage.ts file defines the messages that are sent between the extension and the webview. These messages are used to communicate information and events between the two parts of the extension. The ExtensionMessage interface has a type property that indicates the type of message.\nThe following message types are defined:",
		"crumbs": [
			"Utilities",
			"<span class='chapter-number'>19</span>  <span class='chapter-title'>Extension Messages</span>"
		]
	},
	{
		"objectID": "llm_docs/messages.html#message-types",
		"href": "llm_docs/messages.html#message-types",
		"title": "Extension Messages",
		"section": "",
		"text": "action: Indicates an action that should be performed in the webview. This message type is used to trigger actions in the webview, such as opening a settings page or displaying a dialog.\nstate: Indicates the state of the extension. This message type is used to send the current state of the extension to the webview.\nselectedImages: Indicates the selected images. This message type is used to send the selected images to the extension.\nollamaModels: Indicates the available Ollama models. This message type is used to send the list of available Ollama models to the webview.\nlmStudioModels: Indicates the available LM Studio models. This message type is used to send the list of available LM Studio models to the webview.\ntheme: Indicates the current theme. This message type is used to send the current theme to the webview.\nworkspaceUpdated: Indicates that the workspace has been updated. This message type is used to notify the webview that the workspace has been updated.\ninvoke: Indicates that a function should be invoked in the webview. This message type is used to call a function in the webview from the extension.\npartialMessage: Indicates a partial message. This message type is used to send a partial message to the webview.\nopenRouterModels: Indicates the available OpenRouter models. This message type is used to send the list of available OpenRouter models to the webview.\nglamaModels: Indicates the available Glama models. This message type is used to send the list of available Glama models to the webview.\nunboundModels: Indicates the available Unbound models. This message type is used to send the list of available Unbound models to the webview.\nrequestyModels: Indicates the available Requesty models. This message type is used to send the list of available Requesty models to the webview.\nopenAiModels: Indicates the available OpenAI models. This message type is used to send the list of available OpenAI models to the webview.\nmcpServers: Indicates the available MCP servers. This message type is used to send the list of available MCP servers to the webview.\nenhancedPrompt: Indicates an enhanced prompt. This message type is used to send an enhanced prompt to the webview.\ncommitSearchResults: Indicates the commit search results. This message type is used to send the commit search results to the webview.\nlistApiConfig: Indicates the list of API configurations. This message type is used to send the list of API configurations to the webview.\nvsCodeLmModels: Indicates the available VSCode Language Model models. This message type is used to send the list of available VSCode Language Model models to the webview.\nvsCodeLmApiAvailable: Indicates whether the VSCode Language Model API is available. This message type is used to notify the webview whether the VSCode Language Model API is available.\nrequestVsCodeLmModels: Indicates a request for VSCode Language Model models. This message type is used to request the list of available VSCode Language Model models from the extension.\nupdatePrompt: Indicates an update to a prompt. This message type is used to send an updated prompt to the webview.\nsystemPrompt: Indicates the system prompt. This message type is used to send the system prompt to the webview.\nautoApprovalEnabled: Indicates whether auto approval is enabled. This message type is used to send the auto approval setting to the webview.\nupdateCustomMode: Indicates an update to a custom mode. This message type is used to send an updated custom mode to the webview.\ndeleteCustomMode: Indicates a deletion of a custom mode. This message type is used to notify the webview that a custom mode has been deleted.\ncurrentCheckpointUpdated: Indicates an update to the current checkpoint. This message type is used to send an update to the current checkpoint to the webview.\nshowHumanRelayDialog: Indicates that a human relay dialog should be shown. This message type is used to request the webview to show a human relay dialog.\nhumanRelayResponse: Indicates a response from the human relay dialog. This message type is used to send a response from the human relay dialog to the extension.\nhumanRelayCancel: Indicates that the human relay dialog has been cancelled. This message type is used to notify the extension that the human relay dialog has been cancelled.\nbrowserToolEnabled: Indicates whether the browser tool is enabled. This message type is used to send the browser tool setting to the webview.\nbrowserConnectionResult: Indicates the result of a browser connection. This message type is used to send the result of a browser connection to the webview.\nremoteBrowserEnabled: Indicates whether the remote browser is enabled. This message type is used to send the remote browser setting to the webview.",
		"crumbs": [
			"Utilities",
			"<span class='chapter-number'>19</span>  <span class='chapter-title'>Extension Messages</span>"
		]
	},
	{
		"objectID": "llm_docs/intellij-plugin.html",
		"href": "llm_docs/intellij-plugin.html",
		"title": "How to Create an IntelliJ Plugin from the Roo Code Codebase",
		"section": "",
		"text": "Prerequisites\nThis document provides detailed instructions on how to create an IntelliJ plugin from the Roo Code codebase. This allows developers familiar with the IntelliJ IDEA IDE to leverage the Roo Code functionality within their preferred environment.",
		"crumbs": [
			"Other",
			"<span class='chapter-number'>20</span>  <span class='chapter-title'>How to Create an IntelliJ Plugin from the Roo Code Codebase</span>"
		]
	},
	{
		"objectID": "llm_docs/intellij-plugin.html#prerequisites",
		"href": "llm_docs/intellij-plugin.html#prerequisites",
		"title": "How to Create an IntelliJ Plugin from the Roo Code Codebase",
		"section": "",
		"text": "IntelliJ IDEA IDE: You will need a working installation of IntelliJ IDEA to develop and test the plugin.\nBasic knowledge of IntelliJ plugin development: Familiarity with the IntelliJ Platform SDK and plugin development concepts is essential.",
		"crumbs": [
			"Other",
			"<span class='chapter-number'>20</span>  <span class='chapter-title'>How to Create an IntelliJ Plugin from the Roo Code Codebase</span>"
		]
	},
	{
		"objectID": "llm_docs/intellij-plugin.html#steps",
		"href": "llm_docs/intellij-plugin.html#steps",
		"title": "How to Create an IntelliJ Plugin from the Roo Code Codebase",
		"section": "Steps",
		"text": "Steps\n\nCreate a new IntelliJ plugin project. Use the IntelliJ IDEA IDE to create a new plugin project. Select “New Project” from the File menu, then select “IntelliJ Platform Plugin” from the project types. This will create a basic plugin project with the necessary files and directories.\nIdentify reusable code. The core logic of the Roo Code extension, such as the code for interacting with the LLMs, the MCP integration, and the core utilities, can be reused in the IntelliJ plugin. This code is located in the src directory. Carefully analyze the Roo Code codebase to identify the components that can be adapted for use in the IntelliJ plugin.\nAdapt the VS Code API calls to the IntelliJ API. The VS Code API calls need to be replaced with the corresponding IntelliJ API calls. This will require significant effort, as the two APIs are very different. You will need to consult the IntelliJ Platform SDK documentation to find the appropriate API calls.\nImplement the UI using the IntelliJ UI framework. The webview UI needs to be reimplemented using the IntelliJ UI framework. This will also require significant effort, as the two UI frameworks are very different. You will need to use Swing or JavaFX to create the UI. Consider using existing UI components from the IntelliJ Platform SDK to maintain a consistent look and feel.\nCreate a plugin.xml file. This file describes the plugin to the IntelliJ IDEA IDE. The plugin.xml file should be located in the src/main/resources/META-INF directory. This file defines the plugin’s ID, name, version, vendor, description, dependencies, extensions, and actions.\nBuild and test the plugin. Use the IntelliJ IDEA IDE to build and test the plugin. Select “Build” from the Build menu, then select “Build Project”. To test the plugin, select “Run” from the Run menu, then select “Run”. You can also use the “Debug” menu to debug the plugin.",
		"crumbs": [
			"Other",
			"<span class='chapter-number'>20</span>  <span class='chapter-title'>How to Create an IntelliJ Plugin from the Roo Code Codebase</span>"
		]
	},
	{
		"objectID": "llm_docs/intellij-plugin.html#reusing-code",
		"href": "llm_docs/intellij-plugin.html#reusing-code",
		"title": "How to Create an IntelliJ Plugin from the Roo Code Codebase",
		"section": "Reusing Code",
		"text": "Reusing Code\nThe following code can be reused from the Roo Code codebase:\n\nLLM Interaction Code: The code in the src/api directory can be reused to interact with the LLMs. This code handles the communication with the different LLM providers and provides a consistent interface for accessing the LLMs.\nMCP Integration Code: The code in the src/services/mcp directory can be reused to integrate with the Model Context Protocol (MCP). This code handles the communication with the MCP servers and provides access to the MCP tools and resources.\nCore Utilities: The code in the src/utils directory can be reused for various utility functions. These functions provide common functionalities such as file system operations, string manipulation, and data transformations.",
		"crumbs": [
			"Other",
			"<span class='chapter-number'>20</span>  <span class='chapter-title'>How to Create an IntelliJ Plugin from the Roo Code Codebase</span>"
		]
	},
	{
		"objectID": "llm_docs/intellij-plugin.html#adapting-vs-code-api-calls",
		"href": "llm_docs/intellij-plugin.html#adapting-vs-code-api-calls",
		"title": "How to Create an IntelliJ Plugin from the Roo Code Codebase",
		"section": "Adapting VS Code API Calls",
		"text": "Adapting VS Code API Calls\nThe following VS Code API calls need to be replaced with the corresponding IntelliJ API calls:\n\nvscode.commands.registerCommand: Use com.intellij.openapi.actionSystem.AnAction to register a new action.\nvscode.window.createWebviewPanel: Use com.intellij.openapi.ui.SimpleToolWindowPanel to create a new tool window.\nvscode.ExtensionContext: Use com.intellij.openapi.components.ApplicationComponent or com.intellij.openapi.components.ProjectComponent to access the plugin’s context.",
		"crumbs": [
			"Other",
			"<span class='chapter-number'>20</span>  <span class='chapter-title'>How to Create an IntelliJ Plugin from the Roo Code Codebase</span>"
		]
	},
	{
		"objectID": "llm_docs/intellij-plugin.html#implementing-the-ui",
		"href": "llm_docs/intellij-plugin.html#implementing-the-ui",
		"title": "How to Create an IntelliJ Plugin from the Roo Code Codebase",
		"section": "Implementing the UI",
		"text": "Implementing the UI\nThe webview UI needs to be reimplemented using the IntelliJ UI framework. You can use Swing or JavaFX to create the UI. Consider using existing UI components from the IntelliJ Platform SDK to maintain a consistent look and feel.",
		"crumbs": [
			"Other",
			"<span class='chapter-number'>20</span>  <span class='chapter-title'>How to Create an IntelliJ Plugin from the Roo Code Codebase</span>"
		]
	},
	{
		"objectID": "llm_docs/intellij-plugin.html#plugin.xml",
		"href": "llm_docs/intellij-plugin.html#plugin.xml",
		"title": "How to Create an IntelliJ Plugin from the Roo Code Codebase",
		"section": "plugin.xml",
		"text": "plugin.xml\nThe plugin.xml file describes the plugin to the IntelliJ IDEA IDE. Here is an example plugin.xml file:\n&lt;idea-plugin&gt;\n    &lt;id&gt;com.example.roocode.intellij&lt;/id&gt;\n    &lt;name&gt;Roo Code IntelliJ Plugin&lt;/name&gt;\n    &lt;version&gt;1.0&lt;/version&gt;\n    &lt;vendor email=\"support@example.com\" url=\"http://www.example.com\"&gt;Example&lt;/vendor&gt;\n\n    &lt;description&gt;&lt;![CDATA[\n    This plugin provides AI-powered code assistance for IntelliJ IDEA.\n    ]]&gt;&lt;/description&gt;\n\n    &lt;depends&gt;com.intellij.modules.platform&lt;/depends&gt;\n\n    &lt;extensions defaultExtensionNs=\"com.intellij\"&gt;\n        &lt;!-- Add your extensions here --&gt;\n    &lt;/extensions&gt;\n\n    &lt;actions&gt;\n        &lt;!-- Add your actions here --&gt;\n    &lt;/actions&gt;\n&lt;/idea-plugin&gt;",
		"crumbs": [
			"Other",
			"<span class='chapter-number'>20</span>  <span class='chapter-title'>How to Create an IntelliJ Plugin from the Roo Code Codebase</span>"
		]
	},
	{
		"objectID": "llm_docs/intellij-plugin.html#running-roo-code-in-a-containersandbox",
		"href": "llm_docs/intellij-plugin.html#running-roo-code-in-a-containersandbox",
		"title": "How to Create an IntelliJ Plugin from the Roo Code Codebase",
		"section": "Running Roo Code in a Container/Sandbox",
		"text": "Running Roo Code in a Container/Sandbox\nTo enhance security and isolation, you might consider running the core Roo Code logic (LLM interactions, MCP) within a container or sandbox environment inside the IntelliJ plugin. Here are a few options:\n\nDocker Container: Package the core logic into a Docker container and use the IntelliJ plugin to communicate with the container via a REST API. This provides strong isolation and allows you to manage dependencies separately.\nJVM Sandbox: Use the Java Security Manager or a similar sandboxing mechanism to restrict the access of the Roo Code logic to system resources. This is a lighter-weight option than Docker, but it may not provide as strong isolation.\nGraalVM Native Image: Compile the core Roo Code logic to a native image using GraalVM. This can improve performance and reduce the memory footprint of the plugin.\n\nNote: Due to the significant differences between the VS Code and IntelliJ plugin architectures, it may not be possible to reuse a large portion of the codebase. However, the core logic and utilities can be reused to reduce the amount of code that needs to be rewritten.",
		"crumbs": [
			"Other",
			"<span class='chapter-number'>20</span>  <span class='chapter-title'>How to Create an IntelliJ Plugin from the Roo Code Codebase</span>"
		]
	},
	{
		"objectID": "llm_docs/integrations.html",
		"href": "llm_docs/integrations.html",
		"title": "Integrations Architecture",
		"section": "",
		"text": "Key Components\nThe integrations directory integrates the Roo Code extension with various VS Code features, enhancing the user experience and providing seamless access to VS Code functionalities.",
		"crumbs": [
			"Other",
			"<span class='chapter-number'>21</span>  <span class='chapter-title'>Integrations Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/integrations.html#key-components",
		"href": "llm_docs/integrations.html#key-components",
		"title": "Integrations Architecture",
		"section": "",
		"text": "diagnostics/: This directory contains the code for integrating with VS Code’s diagnostics system, which is used to display errors and warnings in the editor. This allows the extension to provide real-time feedback to the user about potential issues in their code.\n\nExample: The DiagnosticsProvider class might use the VS Code API to create and display diagnostic messages in the editor.\n\neditor/: This directory contains the code for integrating with VS Code’s editor features, such as code actions and completions. This allows the extension to provide intelligent code suggestions and automate common tasks.\n\nExample: The CodeActionProvider class might use the VS Code API to register code actions that can be triggered by the user in the editor.\n\nterminal/: This directory contains the code for integrating with VS Code’s terminal, allowing the extension to interact with the terminal. This enables the extension to execute commands and display the output in the terminal.\n\nExample: The TerminalHandler class might use the VS Code API to create and manage terminal instances.\n\ntheme/: This directory contains the code for customizing the theme of the extension. This allows the extension to provide a consistent look and feel with the VS Code editor.\n\nExample: The ThemeManager class might use the VS Code API to set the colors and fonts of the extension’s UI elements.\n\nworkspace/: This directory contains the code for integrating with VS Code’s workspace features, such as file watching and project management. This allows the extension to monitor changes in the workspace and react accordingly.\n\nExample: The WorkspaceWatcher class might use the VS Code API to listen for file creation, deletion, and modification events.",
		"crumbs": [
			"Other",
			"<span class='chapter-number'>21</span>  <span class='chapter-title'>Integrations Architecture</span>"
		]
	},
	{
		"objectID": "llm_docs/integrations.html#relationships",
		"href": "llm_docs/integrations.html#relationships",
		"title": "Integrations Architecture",
		"section": "Relationships",
		"text": "Relationships\nThe integration components interact with each other and with the core components to provide a seamless experience for the user. For example:\n\nThe diagnostics/ component might use the core/ components to analyze the code and display errors and warnings in the editor.\nThe editor/ component might use the api/ components to interact with the LLMs and provide code suggestions.\nThe terminal/ component might use the core/ components to execute commands and display the output in the terminal.\nThe theme/ component might use the VS Code API to customize the appearance of the extension.\nThe workspace/ component might use the VS Code API to monitor changes in the workspace and update the extension’s state accordingly.",
		"crumbs": [
			"Other",
			"<span class='chapter-number'>21</span>  <span class='chapter-title'>Integrations Architecture</span>"
		]
	}
]
